# name: Scrape and Deploy

# on:
#   schedule:
#     - cron: "0 * * * *"   # every hour
#   workflow_dispatch:       # allow manual run

# jobs:
#   scrape:
#     runs-on: ubuntu-latest
#     permissions:
#       contents: write  # Grant write permission for the default GITHUB_TOKEN

#     steps:
#       - name: Checkout repo
#         uses: actions/checkout@v3

#       - name: Set up Python
#         uses: actions/setup-python@v4
#         with:
#           python-version: "3.10"

#       - name: Install dependencies
#         run: |
#           python -m pip install --upgrade pip
#           pip install selenium undetected-chromedriver

#       - name: Run scraper
#         run: python scraper.py

#       - name: Configure Git
#         run: |
#           git config --global user.name "Scraper Bot"
#           git config --global user.email "bot@example.com"

#       - name: Commit updated CSV
#         run: |
#           git add frontend/public/leaderboard.csv
#           git commit -m "Update leaderboard.csv [skip ci]" || echo "No changes"
#           # Pull the latest changes from the remote before pushing.
#           git pull origin main --rebase
#           git push

#   deploy:
#     runs-on: ubuntu-latest
#     needs: scrape   # only runs after scraping finishes

#     steps:
#       - name: Checkout repo
#         uses: actions/checkout@v3
#         with:
#           token: ${{ secrets.GH_PAT }}

#       - name: Set up Node.js
#         uses: actions/setup-node@v3
#         with:
#           node-version: "18"

#       - name: Install frontend dependencies
#         run: |
#           cd frontend
#           npm install

#       - name: Build React app
#         run: |
#           cd frontend
#           npm run build

#       - name: Deploy to GitHub Pages
#         run: |
#           cd frontend
#           npx gh-pages -d build -u "github-actions-bot <support+actions@github.com>" --repo https://x-access-token:${{ secrets.GH_PAT }}@github.com/nrzdhmz/Scraping_RiskLeaderboard.git


#STOPPED LIVE